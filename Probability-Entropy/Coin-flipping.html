

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Probability, energy and entropy &#8212; Equilibrium Statistical Physics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=bd9e20870c6007c4c509" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=bd9e20870c6007c4c509"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Probability-Entropy/Coin-flipping';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Entropy and information" href="Shannon-entropy-2.html" />
    <link rel="prev" title="Quick Summary of Statistical Mechanics" href="../intro-files/introduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <header>
  
    <div class="bd-header navbar navbar-expand-lg bd-navbar">
    </div>
  
  </header>

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro-files/intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/StatPhys-Logo26.png" class="logo__image only-light" alt="Equilibrium Statistical Physics - Home"/>
    <script>document.write(`<img src="../_static/StatPhys-Logo26.png" class="logo__image only-dark" alt="Equilibrium Statistical Physics - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro-files/intro.html">
                    Lecture Notes on Equilibrium Statistical Mechanics (Physics 211)
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro-files/course-Info-211-2026.html">Course Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro-files/introduction.html">Quick Summary of Statistical Mechanics</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Probability, energy and entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="Shannon-entropy-2.html">Entropy and information</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/Hallatscheklab/StatPhys/blob/master/Probability-Entropy/Coin-flipping.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Hallatscheklab/StatPhys" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Hallatscheklab/StatPhys/issues/new?title=Issue%20on%20page%20%2FProbability-Entropy/Coin-flipping.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Probability-Entropy/Coin-flipping.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Probability, energy and entropy</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coin-flipping">Coin flipping</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coarse-graining">Coarse-graining</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calculation-of-first-and-second-moment">Calculation of first and second moment</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-value">Expectation value</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#variance">Variance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-coin-flips-as-random-walks">Simulating coin-flips as random walks</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="probability-energy-and-entropy">
<h1>Probability, energy and entropy<a class="headerlink" href="#probability-energy-and-entropy" title="Permalink to this heading">#</a></h1>
<p>Agenda:</p>
<ul class="simple">
<li><p>microstates vs macrostates</p></li>
<li><p>emerging collective behavior</p></li>
<li><p>universality (CLT)</p></li>
<li><p>entropy vs energy</p></li>
<li><p>probability recap</p></li>
</ul>
<p>Reading:</p>
<ul class="simple">
<li><p>Arovas, Ch. 1</p></li>
<li><p>Kardar, Ch. 2</p></li>
</ul>
<section id="coin-flipping">
<h2>Coin flipping<a class="headerlink" href="#coin-flipping" title="Permalink to this heading">#</a></h2>
<p>We will use the simple example of repeatedly flipping a biased coin as a warm-up excercise to illustrate key concepts in statistical physics.</p>
<p>Coin flipping arises in many context:</p>
<ul class="simple">
<li><p>spatial configuration of magnetic moments: 1D Ising spin chain</p></li>
<li><p>time series of left- or right steps in a random walk or a polymer (1D freely jointed chain)</p></li>
</ul>
<section id="setup">
<h3>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h3>
<p>We assume that the coin is flipped <span class="math notranslate nohighlight">\(N\)</span> times (~”volume” of spin chain) and describe the outcome of coin flip <span class="math notranslate nohighlight">\(i\)</span> as <span class="math notranslate nohighlight">\(\sigma_{i} \in\{-1,+1\}\)</span>.</p>
<p>For a single coin flip, the probabilities of heads and tails are</p>
<div class="math notranslate nohighlight">
\[\begin{split}P\left(\sigma_{i}\right)=\left\{\begin{array}{l}p \;, \quad\sigma=1 \\ q=1-p\;, \quad \sigma=-1\end{array}\right.\;,\end{split}\]</div>
<p>which can also be concisely expressed as <span class="math notranslate nohighlight">\(P\left(\sigma_{i}\right)=p \cdot \delta_{\sigma_i 1}+q \delta_{\sigma_i 0}\)</span>, which is sometimes useful.</p>
<p>Since coin flips are uncorrelated (by assumption), the probability of observing a particular configuration is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P\left(\sigma_{1}, \sigma_{2}, \ldots\right) &amp; = \prod_{j} P\left(\sigma_{j}\right) \\
&amp; \text { (uncorrelated spins) }
\end{aligned}
\end{split}\]</div>
<p>In principle, everything one can say about the statistics of coin flips follows from this expression.</p>
<p><em>Question:</em> Compare</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; A=\{++--+++-+-+++---+++-+-++-+\} \\
&amp; B=\{++++++++++++++++++++++++++\} \\
&amp; C=\{+-+-+-+-+-+-+-+-+-+-+-+-+-\}
\end{aligned}
\end{split}\]</div>
<p>If <span class="math notranslate nohighlight">\(p=q=\frac{1}{2}, P(A)=P(B)=P(C)\)</span>. So, why does <span class="math notranslate nohighlight">\(B\)</span> (and <span class="math notranslate nohighlight">\(C\)</span>?) look exceptional?</p>
</section>
<section id="coarse-graining">
<h3>Coarse-graining<a class="headerlink" href="#coarse-graining" title="Permalink to this heading">#</a></h3>
<p>In the realm of statistical physics, the concept of <strong>coarse-graining</strong> plays a pivotal role in understanding the transition from microscopic to macroscopic descriptions. The entire configuration of a system, denoted by <span class="math notranslate nohighlight">\(\{\sigma\} = \left\{\sigma_{1}, \sigma_{2}, \ldots\right\}\)</span>, represents the <strong>micro-state</strong>. The set of all micro-states encompasses all possible configurations at the most fundamental level.</p>
<p><strong>However, we are rarely concerned with the exact details of individual microstates. Instead, we focus on features common to all typical microstates.</strong> In most cases, the specific microstate of a system—such as the precise arrangement of spins in a solid or the exact positions and momenta of molecules in a glass of water—offers little insight into its macroscopic behavior. Questions like “What happens to water when it is heated?” or “How does a balloon respond to pressure?” relate to emergent properties derived from the shared characteristics of the vast number of possible microstates in a macroscopic system (on the order of Avogadro’s number).</p>
<p>For instance, when observing a sequence of coin flips represented as 1’s and 0’s, we are generally uninterested in the precise order of outcomes. Instead, we notice patterns, such as the balance between 1’s and 0’s. This leads us to consider quantities like the total number of heads <span class="math notranslate nohighlight">\(N_+\)</span>, tails <span class="math notranslate nohighlight">\(N_-\)</span>, or their difference,</p>
<div class="math notranslate nohighlight">
\[X \equiv \sum_{j=1}^{N} \sigma_{j}=N_+ - N_-\;.\]</div>
<p>Similarly, in a magnet, individual spins are difficult to measure, but we can focus on macroscopic quantities like the magnetization, which is also expressed as <span class="math notranslate nohighlight">\(X = N_+ - N_-\)</span>, the net difference between up and down spins. Note that since, <span class="math notranslate nohighlight">\(N=N_++N_-\)</span>, fixing <span class="math notranslate nohighlight">\(X\)</span> fixes both <span class="math notranslate nohighlight">\(N_+=(N+X)/2\)</span> and <span class="math notranslate nohighlight">\(N_-=(N-X)/2\)</span>.</p>
<p>Since mapping <span class="math notranslate nohighlight">\({\sigma} \rightarrow X\)</span> reduces detailed information to a single summary quantity, <span class="math notranslate nohighlight">\(X\)</span> is known as a macroscopic observable. Fixing <span class="math notranslate nohighlight">\(X\)</span> defines a macrostate, which captures the system’s behavior at a higher level of abstraction. (The associated loss of information is a key quantity central to both information theory and statistical mechanics. More on that later.)</p>
<p><strong>A primary goal in statistical physics is to transition from the probability distribution of microstates, <span class="math notranslate nohighlight">\(P({\sigma})\)</span>, to the probability distribution of macrostates, <span class="math notranslate nohighlight">\(P(X)\)</span>.</strong> Understanding this transformation is central to the discipline. To explore this, consider a coin-flipping example.</p>
<p>The probability of observing a macrostate <span class="math notranslate nohighlight">\(X\)</span> depends on two factors: the number of microstates <span class="math notranslate nohighlight">\(\binom{N}{N_+}\)</span> consistent with <span class="math notranslate nohighlight">\(X\)</span>, and the probability <span class="math notranslate nohighlight">\(p^{N_+}q^{N_-}\)</span> of any specific microstate. This yields the binomial distribution:</p>
<div class="math notranslate nohighlight">
\[
P(X)=\underbrace{\frac{N!}{N_{+}! N_{-}!}}_{\equiv e^{S(X)}} \quad \underbrace{p^{N_{+}}q^{N_{-}}}_{\equiv e^{-E(X)}}
\]</div>
<div class="math notranslate nohighlight">
\[
P(X)= e^{S(X)}e^{-E(X)}
\]</div>
<p>Here, we introduced the quantities <span class="math notranslate nohighlight">\(S(X)\)</span> as the <strong>log of the number of microstates</strong> and <span class="math notranslate nohighlight">\(E(X)\)</span> as the negative of the <strong>log-probability of a single such microstate</strong>. Up to pre-factors, these quantities are <strong>entropy</strong> and <strong>energy</strong> in statistical physics. They always compete with one another ….</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
&amp; S=\ln (N !)-\ln \left(N_{+} !\right)-\ln \left(N_{-} !\right)
\end{aligned}
\]</div>
<p>Now we invoke Stirling’s approximation, which is given by
\begin{aligned}
\ln N !=N(\ln N-1)+O(\ln N)
\end{aligned}
and can be roughly derived as <span class="math notranslate nohighlight">\(\ln N! = \sum_{j=1}^N \ln j \approx \int_1^N dx \ln x = N(\ln N - 1) + 1\)</span>, which successfully captures the leading dependence.</p>
<p>Using Stirling’s approximation, we find for the entropy</p>
<div class="math notranslate nohighlight" id="equation-entropy-coin-flipping">
<span class="eqno">(1)<a class="headerlink" href="#equation-entropy-coin-flipping" title="Permalink to this equation">#</a></span>\[
S \approx-N\left(\frac{1+x}{2} \ln \left(\frac{1+x}{2}\right)+\frac{1-x}{2} \ln \left(\frac{1-x}{2}\right)\right)\;,
\]</div>
<p>where we introduced the specific magnetization <span class="math notranslate nohighlight">\(x=X/N\)</span>.</p>
<p>The energy can be written as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
E(x) &amp; =-\ln \left(p^{N_{+}} q^{N_{-}}\right)=-N_{+} \ln (p)-N_{-} \ln (q) \\
&amp; =-N\left[\frac{1+x}{2} \ln p+\frac{1-x}{2} \ln q\right] \\
&amp; =-\frac{N}{2}\left[\ln (p q)+x \ln \frac{p}{q}\right]
\end{aligned}
\end{split}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For large <span class="math notranslate nohighlight">\(N\)</span>, both entropy <span class="math notranslate nohighlight">\(S\propto N\)</span> and energy <span class="math notranslate nohighlight">\(E\propto N\)</span> have a very simple, linear dependence on <span class="math notranslate nohighlight">\(N\)</span>. Macroscopic observables that grow linearly with the system size are called <strong>extensive</strong>. These are in contrast to <strong>intensive</strong> quanitites, which approach a constant in the thermodynamic limit of large systems, for example <span class="math notranslate nohighlight">\(x=X/N\)</span> which is bounded between -1 and 1.</p>
<p><strong>Throughout this course, we use capital/lower case letters to indicate extensive/intensive quantities.</strong></p>
</div>
<p>The following plots illustrate the competition between energy and entropy.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define the function s(x)</span>
<span class="k">def</span> <span class="nf">s</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">+</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Create an array of x values from -1 to 1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>

<span class="c1"># Avoid division by zero and log of zero by slightly adjusting the range</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.999999</span><span class="p">,</span> <span class="mf">0.999999</span><span class="p">)</span>

<span class="c1"># Compute s(x) for these x values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">s</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="c1"># Define the function e(x) with p = 0.7 and q = 0.3</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">q</span> <span class="o">=</span> <span class="mf">0.3</span>

<span class="k">def</span> <span class="nf">e</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span> <span class="o">*</span> <span class="n">q</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">q</span><span class="p">))</span>

<span class="c1"># Compute e(x) for the same x values</span>
<span class="n">y_e</span> <span class="o">=</span> <span class="n">e</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Compute the sum of s(x) and e(x)</span>
<span class="n">y_sum</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_e</span>

<span class="c1"># Create the plot with s(x), e(x), and their difference</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$s(x)=-\left(\frac{1+x}</span><span class="si">{2}</span><span class="s1"> \ln \left(\frac{1+x}</span><span class="si">{2}</span><span class="s1">\right)+\frac{1-x}</span><span class="si">{2}</span><span class="s1"> \ln \left(\frac{1-x}</span><span class="si">{2}</span><span class="s1">\right)\right)$&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dotted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_e</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$e(x)=-\frac</span><span class="si">{1}{2}</span><span class="s1">\left[\ln (pq)+x \ln \frac</span><span class="si">{p}{q}</span><span class="s1">\right]$&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_sum</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;Difference of $s(x)$ and $e(x)$, which is $\ln P(x)$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Values&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Plot of s(x), e(x), and their difference; p=&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; q=&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/0b7616cce707c6d823564822704b73981963d4b89765d6ac952feb2c7aa8673c.png" src="../_images/0b7616cce707c6d823564822704b73981963d4b89765d6ac952feb2c7aa8673c.png" />
</div>
</div>
<p>Notice:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s(x)\)</span> and <span class="math notranslate nohighlight">\(e(x)\)</span> are the entropy and energy per coin, respectively (see legend).</p></li>
<li><p>The entropy <span class="math notranslate nohighlight">\(s(x)\)</span> has a maximum at the neutral point <span class="math notranslate nohighlight">\(x = 0\)</span> and vanishes at the boundaries (all spin up / down)/</p></li>
<li><p>“Low energy” states have higher probability.</p></li>
<li><p>The competition between <span class="math notranslate nohighlight">\(e(x)\)</span> and <span class="math notranslate nohighlight">\(s(x)\)</span> leads to a maximum in their difference, <span class="math notranslate nohighlight">\(s(x)-e(x)\)</span>.</p></li>
<li><p>Later, we will rather look at the negative, <span class="math notranslate nohighlight">\(e(x)-s(x)=:f(x)\)</span>, which we call a free energy. It is generally a convex function and has a <em>minimum</em> at the most likely value of <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The depicted maximum in <span class="math notranslate nohighlight">\(-f(x)\)</span> does not look very impressive. But, since we have</p>
<div class="math notranslate nohighlight">
\[P(x)=e^{-N f(x)},\]</div>
<p>a so-called (large deviation principle)[<a class="reference external" href="https://en.wikipedia.org/wiki/Large_deviations_theory">https://en.wikipedia.org/wiki/Large_deviations_theory</a>], we will get a pronounced maximum at <span class="math notranslate nohighlight">\(x=p-q\)</span> (the minimum of <span class="math notranslate nohighlight">\(f(x)\)</span>) for even modestly large <span class="math notranslate nohighlight">\(N\)</span>. Fully deterministic behavior <span class="math notranslate nohighlight">\(x \to p-q\)</span> emerges in the thermodynamic limit, <span class="math notranslate nohighlight">\(N\to \infty\)</span>. The most likely value of <span class="math notranslate nohighlight">\(x\)</span> coincides with the expectation value <span class="math notranslate nohighlight">\(\langle x \rangle = p-q\)</span> (see below).</p>
</div>
<p>We can explore the effects of finite <span class="math notranslate nohighlight">\(N\)</span> by Taylor expanding <span class="math notranslate nohighlight">\(S(x)-E(x)\)</span> to <span class="math notranslate nohighlight">\(O(\Delta x^2)\equiv O\left[(x-\langle x\rangle)^{2}\right]\)</span>, we obtain to leading order a Gaussian,</p>
<div class="math notranslate nohighlight">
\[
P(x) \approx C e^{-\left[\frac{(\Delta x)^{2}}{2 \langle \Delta x^2 \rangle}+O\left(N \Delta x^3 \right)\right]} \;,
\]</div>
<p>whose spread is controlled by the variance <span class="math notranslate nohighlight">\(\langle \Delta x^2\rangle = 4pq N^{-1}\)</span>. The first non-Gaussian correction in the exponent, <span class="math notranslate nohighlight">\(N\Delta x^3\)</span>, becomes <span class="math notranslate nohighlight">\(O(1)\)</span> only for fluctuations of size <span class="math notranslate nohighlight">\(\Delta x=O(N^{-1/3})\)</span>. For such fluctuations, the leading Gaussian contribution scales as <span class="math notranslate nohighlight">\(-N\Delta x^2= -O(N^{1/3})\)</span>, which is large and negative when <span class="math notranslate nohighlight">\(N\)</span> is large. Hence, for large <span class="math notranslate nohighlight">\(N\)</span>, appreciable non-Gaussian fluctuations are exceedingly rare.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>One can show that, quite generally, large sums of random variables tend to Gaussians if correlations are short ranged. This is a consequence of the Central Limit Theorem (CLT). The Gaussian is completely fixed by knowing the first and second moment of the distribution. Since the first two moments can often be determined quite easily (see below), this is a great advantage for calculations. The scaling <span class="math notranslate nohighlight">\(\langle \Delta x^2\rangle\sim N^{-1/2}\)</span> and the fact that the limiting distribution is independent of the higher order details of the distributions of individual random numbers is a first example of <strong>universality</strong>. See Section 1.5 of Arovas for a clear mathematical demonstration of the CLT.</p>
</div>
<section id="calculation-of-first-and-second-moment">
<h4>Calculation of first and second moment<a class="headerlink" href="#calculation-of-first-and-second-moment" title="Permalink to this heading">#</a></h4>
<p>The <span class="math notranslate nohighlight">\(n^\text{th}\)</span> moment of a random variable X is defined by <span class="math notranslate nohighlight">\(\langle X^n\rangle\)</span>. The first and second moment of a distribution can often be computed analytically, and those are needed in the context of the CLT. Higher order moments are often more challenging to obtain.</p>
<section id="expectation-value">
<h5>Expectation value<a class="headerlink" href="#expectation-value" title="Permalink to this heading">#</a></h5>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\langle X\rangle &amp; =\sum_{\{\sigma\}} P(\{\sigma\}) X(\{\sigma\}) \\
&amp; =\sum_{\{\sigma\}}\left[\prod_{j} P\left(\sigma_{j}\right)\right]\left[\sum_{i} \sigma_{i}\right] \\
&amp; =\sum_{j} \sum_{\sigma_{j}} P\left(\sigma_{j}\right) \cdot \sigma_{j} \\
&amp; =\sum_{j}(p-q)=N(p-q)
\end{aligned}
\end{split}\]</div>
<p>So, we see that the expectation value of X is an <strong>extensive</strong> quantity.</p>
<p>Of course, a particular realization will (usually!) not have <span class="math notranslate nohighlight">\(X=\langle X\rangle\)</span>.</p>
<p>One measure of spread is the</p>
</section>
<section id="variance">
<h5>Variance<a class="headerlink" href="#variance" title="Permalink to this heading">#</a></h5>
<div class="math notranslate nohighlight">
\[
\operatorname{var}(X) \equiv\langle\underbrace{(X-\langle X\rangle)^{2}}_{\equiv \Delta X^2}\rangle=\left\langle X^{2}\right\rangle-\langle X\rangle^{2} .
\]</div>
<p>To compute <span class="math notranslate nohighlight">\(\left\langle X^{2} \right\rangle\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
&amp; \left\langle X^{2}\right\rangle=\sum_{\{\sigma\}} P(\{\sigma\}) X^{2}(\{\sigma\}) \\
&amp; =\sum_{\{ \sigma \}} P(\{\sigma\}) \sum_{i, j} \sigma_{i} \cdot \sigma_{j}=\sum_{i, j}\left\langle\sigma_{i} \sigma_{j}\right\rangle 
\end{aligned}
\end{split}\]</div>
<p>if <span class="math notranslate nohighlight">\(i=j: \sigma_{i} \cdot \sigma_{i}=1 \text {, so }\left\langle\sigma_{i} \cdot \sigma_{i}\right\rangle=1\)</span></p>
<p>if <span class="math notranslate nohighlight">\(j\neq j: \left\langle\sigma_{i} \sigma_{j}\right\rangle=\left\langle\sigma_{i}\right\rangle\left\langle\sigma_{i}\right\rangle=(p-q)^{2}\)</span></p>
<p>So, <span class="math notranslate nohighlight">\(\left\langle X^{2}\right\rangle=N+N(N-1)(p-q)^{2}\)</span>
v. <span class="math notranslate nohighlight">\(\langle X\rangle^{2}=N^{2}(p-q)^{2}\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\left\langle X^{2}\right\rangle-\langle X\rangle^{2} &amp; =N\left(1-(p-q)^{2}\right) . \\
\operatorname{var}(X) &amp; =4 Npq .
\end{aligned}
\end{split}\]</div>
<p>Note:</p>
<ul class="simple">
<li><p>Since <span class="math notranslate nohighlight">\(\Delta X \propto \sqrt{N}\)</span> but <span class="math notranslate nohighlight">\(\langle X\rangle\propto N\)</span>, we have <span class="math notranslate nohighlight">\(\frac{\Delta x}{\langle x\rangle} \sim N^{-1/2}\rightarrow 0\)</span> for <span class="math notranslate nohighlight">\(p \neq q\)</span> as <span class="math notranslate nohighlight">\(N\to \infty\)</span>.</p></li>
<li><p>The variance of the specific magnetization <span class="math notranslate nohighlight">\(x=X/N\)</span> follows as <span class="math notranslate nohighlight">\(\langle \Delta x^2 \rangle=4pq N^{-1}\)</span>, and appeared in the Gaussian pdf above. The typical spread ~<span class="math notranslate nohighlight">\(N^{-1/2}\)</span> of intensive quantities is general consequence of the Central Limit Theorem.</p></li>
</ul>
</section>
</section>
</section>
<section id="simulating-coin-flips-as-random-walks">
<h3>Simulating coin-flips as random walks<a class="headerlink" href="#simulating-coin-flips-as-random-walks" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parameters</span>
<span class="n">S</span> <span class="o">=</span> <span class="mi">10000</span>  <span class="c1"># Number of samples (sequences)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>   <span class="c1"># Length of each sequence</span>
<span class="n">Q</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Number of sequences to plot</span>

<span class="c1"># Parameters for the biased coin</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># Probability of getting +1 (heads)</span>
<span class="n">q</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span>  <span class="c1"># Probability of getting -1 (tails)</span>

<span class="c1"># Generate S samples of N biased coin flips</span>
<span class="n">biased_coin_flips</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">])</span>

<span class="c1"># Plot 1: Sum of sigma_j from j=1 to k for Q of the S sequences (with biased coin)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Q</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">biased_coin_flips</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Sequence </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$k$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Cumulative Sum $\sum_{j=1}^k \sigma_j$&#39;</span><span class="p">)</span> <span class="c1">#&#39;Cumulative Sum of Sigma_j&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cumulative Sum of Biased Coin Flips for Q=</span><span class="si">{</span><span class="n">Q</span><span class="si">}</span><span class="s1"> Sequences (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot 2: Histogram of the total sum of the sigmas of all sequences (with biased coin)</span>
<span class="n">biased_total_sums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">biased_coin_flips</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">biased_total_sums</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Total Sum of Sigmas&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Histogram of Total Sum of Sigmas for All Sequences (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e7f950ecb425a94616c864bff0fd01e93abe9bc2fa20e511ad3a8195a01f4884.png" src="../_images/e7f950ecb425a94616c864bff0fd01e93abe9bc2fa20e511ad3a8195a01f4884.png" />
<img alt="../_images/e6fb371931e228eeace8f012cb122f7903a91181ad99803eee53c1fdab3081a6.png" src="../_images/e6fb371931e228eeace8f012cb122f7903a91181ad99803eee53c1fdab3081a6.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="c1"># Theoretical expectation for the probability distribution of the sum of sigmas</span>
<span class="c1"># The sum of S sigmas is equivalent to the number of heads minus the number of tails.</span>
<span class="c1"># This can be modeled by a binomial distribution, where &#39;success&#39; is getting a head (+1).</span>
<span class="c1"># The total sum can range from -N (all tails) to +N (all heads).</span>
<span class="c1"># The probability of k heads is binom.pmf(k, N, p), where k ranges from 0 to N.</span>

<span class="c1"># Adjusting k to represent the sum of sigmas: k heads and N-k tails gives a sum of 2k-N.</span>
<span class="c1"># The theoretical probabilities need to be scaled accordingly.</span>
<span class="n">theoretical_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">scaled_sums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span> <span class="o">*</span> <span class="n">k</span> <span class="o">-</span> <span class="n">N</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>

<span class="c1"># Plotting the histogram with the theoretical distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">biased_total_sums</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Empirical Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">scaled_sums</span><span class="p">,</span> <span class="n">theoretical_probs</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Theoretical Distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Total Sum of Sigmas&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Histogram and Theoretical Distribution of Total Sum of Sigmas (p=</span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fd14fcf81a4117ea67ae5ef29f82b368a04522a70297cfe5d366e1bbc5c59389.png" src="../_images/fd14fcf81a4117ea67ae5ef29f82b368a04522a70297cfe5d366e1bbc5c59389.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Probability-Entropy"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../intro-files/introduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Quick Summary of Statistical Mechanics</p>
      </div>
    </a>
    <a class="right-next"
       href="Shannon-entropy-2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Entropy and information</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coin-flipping">Coin flipping</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#coarse-graining">Coarse-graining</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calculation-of-first-and-second-moment">Calculation of first and second moment</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-value">Expectation value</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#variance">Variance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-coin-flips-as-random-walks">Simulating coin-flips as random walks</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Oskar Hallatschek
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=bd9e20870c6007c4c509"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=bd9e20870c6007c4c509"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>